{
  "hash": "84eb074134bcde2b30eded1a199d36a7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"The OpenAI API\"\nformat: \n    revealjs:\n        theme: default\n        chalkboard: true\n        footer: \"Seminar: LLM, WiSe 2024/25\"\n        logo: ../../assets/logo.svg\n        fig-align: center\n---\n\n\n## Let's get started \n\nThe great thing about APIs is that we can start right away without too much preparation! \n\nIn this sprint, we will use the OpenAI API for completions and embeddings.\n\nResource: [OpenAI API docs](https://platform.openai.com/docs/introduction){.external}\n\n## Authentication\n\nTypically, it's as simple as this:\n\n::: {#1a519b58 .cell execution_count=1}\n``` {.python .cell-code}\n# setting up the client in Python\nimport os\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n```\n:::\n\n\n## Authentication for the seminar\nFor the sprint, we have hosted some models in Azure. \n\n::: {#cf7c6700 .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nfrom llm_utils.client import get_openai_client, OpenAIModels\n\nprint(f\"GPT3: {OpenAIModels.GPT_3.value}\")\nprint(f\"GPT4: {OpenAIModels.GPT_4.value}\")\nprint(f\"Embedding model: {OpenAIModels.EMBED.value}\")\n\nMODEL = OpenAIModels.GPT_4.value\n\nclient = get_openai_client(\n    model=MODEL,\n    config_path=os.environ.get(\"CONFIG_PATH\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGPT3: gpt3\nGPT4: gpt4\nEmbedding model: embed\n```\n:::\n:::\n\n\n## Creating a completion\n\n::: {#b8c6b02b .cell execution_count=3}\n``` {.python .cell-code}\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"How old is the earth?\",\n        }\n    ],\n    model=MODEL \n)\n\n# check out the type of the response\n\nprint(f\"Response: {type(chat_completion)}\") # a ChatCompletion object\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: <class 'openai.types.chat.chat_completion.ChatCompletion'>\n```\n:::\n:::\n\n\n## Retrieving the response \n\n::: {#59765b4f .cell execution_count=4}\n``` {.python .cell-code}\n# print the message we want\nprint(f\"\\nResponse message: {chat_completion.choices[0].message.content}\")\n\n# check the tokens used \nprint(f\"\\nTotal tokens used: {chat_completion.usage.total_tokens}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nResponse message: The Earth is approximately 4.54 billion years old.\n\nTotal tokens used: 25\n```\n:::\n:::\n\n\n",
    "supporting": [
      "openai_api_files"
    ],
    "filters": [],
    "includes": {}
  }
}