{
  "hash": "e32b6140db773e321c68a61d39d96750",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Prompting & Parameterization\"\nformat: \n    revealjs:\n        theme: default\n        chalkboard: true\n        footer: \"Seminar: LLM, SoSe 2025\"\n        logo: ../../assets/logo.svg\n        fig-align: center\n---\n\n\n# Prompting \n::: {.callout-note}\n_The following is taken from the [OpenAI Guide](https://platform.openai.com/docs/guides/prompt-engineering){.external}_\n:::\n\n## Write clear instructions\nThese models can’t read your mind. If outputs are too long, ask for brief replies. If you dislike the format, demonstrate the format you’d like to see.\n\n- Include details in your query to get more relevant answers\n- Ask the model to adopt a persona\n- Use delimiters to clearly indicate distinct parts of the input\n- Specify the steps required to complete a task\n- Provide examples\n- Specify the desired length of the output\n\n## Provide reference text\nLanguage models can confidently invent fake answers, especially when asked about esoteric topics or for citations and URLs. In the same way that a sheet of notes can help a student do better on a test, providing reference text to these models can help in answering with fewer fabrications.\n\n- Instruct the model to answer using a reference text\n- Instruct the model to answer with citations from a reference text\n\n\n## Split tasks into simpler subtasks\nComplex tasks tend to have higher error rates than simpler tasks. But they can often be re-defined as a workflow of simpler tasks in which the outputs of earlier tasks are used to construct the inputs to later tasks.\n\n- Use intent classification to identify the most relevant instructions for a user query\n- For dialogue applications that require very long conversations, summarize or filter previous dialogue\n- Summarize long documents piecewise and construct a full summary recursively\n\n\n## Give the model time to \"think\"\nAsking for a \"chain of thought\" before an answer can help the model reason its way toward correct answers more reliably.\n\n- Instruct the model to work out its own solution before rushing to a conclusion\n- Use inner monologue or a sequence of queries to hide the model's reasoning process\n- Ask the model if it missed anything on previous passes\n\n\n## Use external tools\nCompensate for the weaknesses of the model by feeding it the outputs of other tools. \n\n- Use embeddings-based search to implement efficient knowledge retrieval\n- Use code execution to perform more accurate calculations or call external APIs\n- Give the model access to specific functions\n\n\n## Test changes systematically\nImproving performance is easier if you can measure it. In some cases a modification to a prompt will achieve better performance on a few isolated examples but lead to worse overall performance on a more representative set of examples. Therefore to be sure that a change is net positive to performance it may be necessary to define a comprehensive test suite (also known an as an \"eval\").\n\n- Evaluate model outputs with reference to gold-standard answers\n\n\n# Parameterization\n\n## Parameters 1\n**Temperature** (`temperature`): \n\n- Controls the randomness of the generated text \n- Lower temperatures = deterministic outputs \n- Higher temperatures = more randomness\n- Balance between safety and creativity\n\n**Max Tokens** (`max_tokens`): \n\n- Limits the maximum length of the generated text\n\n\n## Parameters 2\n**Top P (Nucleus Sampling)** (`top_p`):\n\n- Dynamically selects a subset of the most likely tokens based on their cumulative probability \n- Ensures diversity in the generated text while still prioritizing tokens with higher probabilities\n- For generating diverse and contextually relevant responses\n\n**Stop Sequence** (`stop`): \n\n- Specifies a sequence of tokens that, if generated by the model, signals it to stop \n\n## Parameters 3\n**Frequency Penalty** (`frequency_penalty`): \n\n- Penalizes tokens based on their frequency in the generated text \n- Discourage the model from repeatedly generating common or redundant tokens\n- Promote diversity in the generated text\n\n**Presence Penalty** (`presence_penalty`): \n\n- Penalizes tokens that are already in the input prompt\n- Discourages the model from simply echoing the input text\n\n\n# Roles \n\n\n## OpenAI chat roles\n- Define different roles in the chat\n- Roles: `system`, `assistant`, `user`, `tools`\n\n**User Role**\n\n- Corresponds to the actual user prompting the model.\n- Inputs queries or prompts to the model.\n\n**Assistant Role**\n\n- Model responds to user queries or prompts.\n- Provides answers and assistance to the user.\n\n## OpenAI chat roles\n\n**System Role**\n\n- Provides additional instructions to the model.\n- Not a user input.\n- Example: Setting response style.\n\n**Tools Role**\n\n- Used for debugging or monitoring purposes.\n- Provides insights into model behavior or performance.\n\n## Code\n\n::: {#5c897ba9 .cell output-location='fragment' execution_count=1}\n``` {.python .cell-code}\nimport os\nfrom llm_utils.client import get_openai_client\n\nMODEL = os.environ.get(\"MODEL\")\n\nclient = get_openai_client(\n    model=MODEL,\n    config_path=os.environ.get(\"CONFIG_PATH\")\n)\n\ncompletion = client.chat.completions.create(\n  model=\"MODEL\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are an annoyed technician working in a help center for dish washers, who answers in short, unfriendly bursts.\"},\n    {\"role\": \"user\", \"content\": \"My dish washer does not clean the dishes, what could be the reason.\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCheck if the spray arms are blocked or the filter is clogged. Make sure you're using the right detergent and that there's enough water pressure.\n```\n:::\n:::\n\n\n# Function calling\n\n## Get more consistent output of language models\n- So far: language model \"freely\" answering\n- Not always a practical format if we want to use a language model for very specific purposes\n- Business applications often require consistent output\n\n## Example: Sentiment analysis\n\n::: {#ee94097a .cell execution_count=2}\n``` {.python .cell-code}\nsentiment_categories = [\"positive\", \"negative\", \"neutral\", \"mixed\"]\n```\n:::\n\n\n&nbsp;\n\n\n\n::: {#c6297f79 .cell execution_count=4}\n``` {.python .cell-code}\nmessages = []\nmessages.append(\n    {\"role\": \"system\", \"content\": f\"Classify the given text into one of the following sentiment categories: {sentiment_categories}.\"}\n)\nmessages.append(\n    {\"role\": \"user\", \"content\": \"I really did not like the movie.\"}\n)\n\nresponse = client.chat.completions.create(\n    messages=messages,\n    model=MODEL\n)\n\nprint(f\"Response: '{response.choices[0].message.content}'\")\n```\n:::\n\n\n::: {#91d766e2 .cell execution_count=5}\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: 'Category: Negative'\n```\n:::\n:::\n\n\n## Function calling\n\n- OpenAI allows for \"function calling\" or \"tool calling\" \n- This allows us to specify the output format of GPT\n- [Function calling (cookbook)](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models){.external}\n- [Function calling](https://platform.openai.com/docs/guides/function-calling){.external}\n\n## Example: continued\n\n::: {#b60d8728 .cell execution_count=6}\n``` {.python .cell-code}\n# this looks intimidating but isn't that complicated\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"analyze_sentiment\",\n            \"description\": \"Analyze the sentiment in a given text.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"sentiment\": {\n                        \"type\": \"string\",\n                        \"enum\": sentiment_categories,\n                        \"description\": f\"The sentiment of the text.\"\n                    }\n                },\n                \"required\": [\"sentiment\"],\n            }\n        }\n    }\n]\n```\n:::\n\n\n---\n\n::: {#fbf40609 .cell execution_count=7}\n``` {.python .cell-code}\nmessages = []\nmessages.append(\n    {\"role\": \"system\", \"content\": f\"Classify the given text into one of the following sentiment categories: {sentiment_categories}.\"}\n)\nmessages.append(\n    {\"role\": \"user\", \"content\": \"I really did not like the movie.\"}\n)\n\nresponse = client.chat.completions.create(\n    messages=messages,\n    model=MODEL,\n    tools=tools,\n    tool_choice={\n        \"type\": \"function\", \n        \"function\": {\"name\": \"analyze_sentiment\"}}\n)\n\nprint(f\"Response: '{response.choices[0].message.tool_calls[0].function.arguments}'\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: '{\"sentiment\":\"negative\"}'\n```\n:::\n:::\n\n\n--- \n\n::: {#85d4eddc .cell execution_count=8}\n``` {.python .cell-code}\nimport json \nresult = json.loads(response.choices[0].message.tool_calls[0].function.arguments) # remember that the answer is a string\nprint(result[\"sentiment\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnegative\n```\n:::\n:::\n\n\n## Including multiple parameters\n\n::: {#0c051979 .cell execution_count=9}\n``` {.python .cell-code}\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"analyze_sentiment\",\n            \"description\": \"Analyze the sentiment in a given text.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"sentiment\": {\n                        \"type\": \"string\",\n                        \"enum\": sentiment_categories,\n                        \"description\": f\"The sentiment of the text.\"\n                    },\n                    \"reason\": {\n                        \"type\": \"string\",\n                        \"description\": \"The reason for the sentiment in few words. If there is no information, do not make assumptions and leave blank.\"\n                    }\n                },\n                \"required\": [\"sentiment\", \"reason\"],\n            }\n        }\n    }\n]\n```\n:::\n\n\n--- \n\n::: {#08e4aa18 .cell execution_count=10}\n``` {.python .cell-code}\nmessages = []\nmessages.append(\n    {\"role\": \"system\", \"content\": f\"Classify the given text into one of the following sentiment categories: {sentiment_categories}. If you can, also extract the reason.\"}\n)\nmessages.append(\n    {\"role\": \"user\", \"content\": \"I loved the movie, Johnny Depp is a great actor.\"}\n)\n\nresponse = client.chat.completions.create(\n    messages=messages,\n    model=MODEL,\n    tools=tools,\n    tool_choice={\n        \"type\": \"function\", \n        \"function\": {\"name\": \"analyze_sentiment\"}}\n)\n\nprint(f\"Response: '{response.choices[0].message.tool_calls[0].function.arguments}'\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse: '{\"sentiment\":\"positive\",\"reason\":\"The text expresses love for the movie and admiration for Johnny Depp.\"}'\n```\n:::\n:::\n\n\n",
    "supporting": [
      "prompting_functions_files"
    ],
    "filters": [],
    "includes": {}
  }
}