{
  "hash": "2641c2092586c91c7b892401fcf1812a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Visualization & clustering of embeddings\nformat:\n  html:\n    code-fold: false\n---\n\n## Visualization of embeddings\n\n::: {#c274dbd5 .cell execution_count=1}\n``` {.python .cell-code}\n# prerequisites\n\nimport os\nfrom llm_utils.client import get_openai_client, OpenAIModels\n\nMODEL = OpenAIModels.EMBED.value\n\n# get the OpenAI client\nclient = get_openai_client(\n    model=MODEL,\n    config_path=os.environ.get(\"CONFIG_PATH\")\n)\n```\n:::\n\n\n::: {#67f8f501 .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nfrom sklearn.manifold import TSNE\n```\n:::\n\n\n::: {#a7acae04 .cell execution_count=3}\n``` {.python .cell-code}\n# Define a list of words to visualize\nwords = [\"king\", \"queen\", \"man\", \"woman\", \"apple\", \"banana\", \"grapes\", \"cat\", \"dog\", \"happy\", \"sad\"]\n\n# Get embeddings for the words\nresponse = client.embeddings.create(\n    input=words,\n    model=MODEL\n)\n\nembeddings = [emb.embedding for emb in response.data]\n```\n:::\n\n\n::: {#cell-tsne-visualization .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.manifold import TSNE\n\n# Apply t-SNE dimensionality reduction\ntsne = TSNE(\n    n_components=2, \n    random_state=42,\n    perplexity=5 # see documentation to set this correctly\n)\nembeddings_2d = tsne.fit_transform(np.array(embeddings))\n\n# Plot the embeddings in a two-dimensional scatter plot\nplt.figure(figsize=(10, 8))\nfor i, word in enumerate(words):\n    x, y = embeddings_2d[i]\n    plt.scatter(x, y, marker='o', color='red')\n    plt.text(x, y, word, fontsize=9)\n\nplt.xlabel(\"t-SNE dimension 1\")\nplt.ylabel(\"t-SNE dimension 2\")\nplt.grid(True)\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![t-SNE visualization of word embeddings](visualization_files/figure-html/tsne-visualization-output-1.png){#tsne-visualization width=789 height=629}\n:::\n:::\n\n\n## Clustering of embeddings\n\n::: {#a5570feb .cell execution_count=5}\n``` {.python .cell-code}\n# do the clustering\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\nn_clusters = 5\n\n# define the model\nkmeans = KMeans(\n  n_clusters=n_clusters,\n  n_init=\"auto\",\n  random_state=2 # do this to get the same output\n)\n\n# fit the model to the data\nkmeans.fit(np.array(embeddings))\n\n# get the cluster labels\ncluster_labels = kmeans.labels_\n```\n:::\n\n\n::: {#cell-tsne-visualization of clustering .cell execution_count=6}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nfrom sklearn.manifold import TSNE\n\n# Apply t-SNE dimensionality reduction\ntsne = TSNE(\n  n_components=2, \n  random_state=42,\n  perplexity=5 # see documentation to set this correctly\n)\nembeddings_2d = tsne.fit_transform(np.array(embeddings))\n\n# Define a color map for clusters\ncolors = plt.cm.viridis(np.linspace(0, 1, n_clusters))\n\n# Plot the embeddings in a two-dimensional scatter plot\nplt.figure(figsize=(10, 8))\nfor i, word in enumerate(words):\n    x, y = embeddings_2d[i]\n    cluster_label = cluster_labels[i]\n    color = colors[cluster_label]\n    plt.scatter(x, y, marker='o', color=color)\n    plt.text(x, y, word, fontsize=9)\n\nplt.xlabel(\"t-SNE dimension 1\")\nplt.ylabel(\"t-SNE dimension 2\")\nplt.grid(True)\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![t-SNE visualization of word embedding clusters](visualization_files/figure-html/tsne-visualization-of-clustering-output-1.png){#tsne-visualization-of-clustering width=789 height=629}\n:::\n:::\n\n\n",
    "supporting": [
      "visualization_files"
    ],
    "filters": [],
    "includes": {}
  }
}