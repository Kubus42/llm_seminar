{
  "hash": "981c525ea20c08d2a63128f65a3786ee",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Embeddings\"\nformat:\n  html:\n    code-fold: false\njupyter: python3\n---\n\n\n\n\nLet us quickly re-visit the concept of embeddings we have already encountered before.\nWe have seen them as a means of transforming text into numerical vectors that can be fed to neural network architectures for language models.\nBut interestingly, we can do a lot more with embeddings than simply this. \n\nOne of the key benefits of embeddings is their ability to capture semantic similarities and relationships between words. \nWhen created with an appropriate model, embeddings do not only transform text into vectors, but they do it while **compressing** the contained information.\nMore simply put, words with similar meanings or contexts tend to have embeddings that are close together in the vector space, while words with different meanings are farther apart. \nThis enables algorithms (and us!) to perform tasks such as word similarity calculation more effectively.\nBut let's start with a quick recap of what embeddings are.\n\n\n## What are embeddings? \nAs mentioned, embeddings play a crucial role in representing words as dense vectors in a continuous vector space. \nWhile, for example, the bag of words model has been a simple and widely-used approach for representing text, it has its limitations, including a fixed vocabulary and the inability to capture nuanced semantic relationships between words.\nEmbeddings address these shortcomings by leveraging the power of **contextual representations**. \nInstead of representing each word in the vocabulary as a one-hot encoded vector, where each word is represented by a binary vector with a dimension equal to the vocabulary size, embeddings generate dense vector representations for words that encode rich semantic information.\n\nUnlike the bag of words model, embeddings are thus context-aware, meaning they capture the meaning of words based on their surrounding context in the text. \nThis contextual understanding allows embeddings to capture subtle semantic relationships between words, such as synonymy, antonymy, and semantic similarity.\nMoreover, embeddings offer a more compact representation of words compared to the sparse vectors used in the bag of words model. \nBy compressing the information into dense vectors of fixed dimensionality, embeddings reduce the dimensionality of the input space, making it more manageable for downstream tasks and allowing for more efficient computation.\n\nThere are plenty of different approaches to generate embeddings, and often embeddings are created as some sort of byproduct of training large. language models.\nAs an example, we will have a quick look at Word2Vec, which is a popular technique for generating word embeddings based on distributed representations of words in a continuous vector space. \nThe key idea behind Word2Vec is to train a neural network model to predict the surrounding words (context) of a given target word in a large corpus of text. \nThis process can be done using either the continuous bag of words (CBOW) or skip-gram architectures. \nIn the CBOW model, the input is the context words, and the output is the target word, while in the skip-gram model, the input is the target word, and the output is the context words. \nBy training the model on a large corpus of text, Word2Vec then learns to encode semantic relationships between words in the form of dense vector representations, our embeddings. \n\nBut, of course, embeddings can also be obtained by transformer architectures such as GPT. \nWe will use the embeddings provided by [OpenAI](https://platform.openai.com/docs/guides/embeddings){.external} for some demonstration.\n\n\n## Matching with embeddings\nLet's do a quick example and re-visit our idea of matching a search prompt with documents.\nIn the previous section we have used a bag of words to compare the three texts to the prompt and realized that this technique is not particularly good. \nUsing embeddings, we can do the same and be a lot better.\n\n::: {#ccd20509 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nTrue\n```\n:::\n:::\n\n\n::: {#bf18231d .cell execution_count=2}\n``` {.python .cell-code}\ntexts = [\n  \"This is the first document.\",\n  \"This document is the second document.\",\n  \"And this is the third one.\"\n]\n\nprompt = \"Is this the first document?\"\n```\n:::\n\n\n::: {#a346fa8a .cell execution_count=3}\n``` {.python .cell-code}\n# prerequisites\nimport os\nfrom openai import OpenAI\n\nMODEL = \"text-embedding-3-small\" # choose the embedding model\n\n# get the OpenAI client\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")    \n)\n```\n:::\n\n\n::: {#621ada71 .cell execution_count=4}\n``` {.python .cell-code}\n# get the embeddings\nresponse = client.embeddings.create(\n    input=texts,\n    model=MODEL\n)\n\ntext_embeddings = [emb.embedding for emb in response.data]\n\nresponse = client.embeddings.create(\n    input=[prompt],\n    model=MODEL\n)\n\nprompt_embedding = response.data[0].embedding\n```\n:::\n\n\n::: {#f9437bdc .cell execution_count=5}\n``` {.python .cell-code}\nimport numpy as np\n\ndef cosine_similarity(vec1: np.array, vec2: np.array) -> float: \n    return np.dot(vec1, vec2) / ( np.linalg.norm(vec1) * np.linalg.norm(vec2) )\n\n\nfor text, text_embedding in zip(texts, text_embeddings):\n    similarity = cosine_similarity(text_embedding, prompt_embedding)\n    print(f\"{text}: {round(similarity, 2)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is the first document.: 0.89\nThis document is the second document.: 0.65\nAnd this is the third one.: 0.33\n```\n:::\n:::\n\n\nAs we can see, there is a clear winner in terms of similarity, and that would have been exactly the document we would have needed.\nSo embeddings provide a great tool to identify matching documents (or texts in general), and are applicable in many different use cases. \nAn almost classic one is creating a chatbot, that can answer questions based on documents: \nWhen a user provides a prompt, we use embeddings to find the best matching documents, and then use the content to provide an answer. \nAn example can be found [here](https://platform.openai.com/docs/tutorials/web-qa-embeddings){.external}.\n\n",
    "supporting": [
      "embeddings_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}