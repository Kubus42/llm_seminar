{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exercise: Sentence tokenization\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-overflow: wrap\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Write a sentence tokenizer that takes the given paragraph and tokenizes it into *sentences*. Then, count the number of sentences and display the result.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Start with just a simple punctuation (`.`) as the delimiter for sentences.\n",
    "- Check out the regex library `re` and the function `re.split` to include also other delimiters. Try out the following regex `r'[.:;!?]\\s*'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"The distant planet, its surface shrouded in mystery and intrigue! With its swirling clouds and alien landscapes, the planet: a tantalizing enigma to explorers and scientists alike? Oh, the wonders it conceals: ancient ruins and extraterrestrial life forms, waiting to be discovered! As the spacecraft descended through the atmosphere, anticipation filled the hearts of the crew. Little did they know, their journey was about to unveil secrets beyond their wildest imagination.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "script_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
