{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Exercise: Word matching\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "    code-overflow: wrap\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** For each element of the following list of keywords, determine whether it is contained in the text.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Transform the text to lower case and use a tokenizer to split the text into word tokens.\n",
    "- First, use a simple comparison of strings to check whether the keywords match any token. When does this approach fail? \n",
    "- Lemmatize the tokens from your text in order to handle some more matching cases. When does this approach still fail? Hint: Use the different options for `pos` in order to handle different types of words such as nouns, verbs etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The company's latest quarterly earnings reports exceeded analysts' expectations, driving up the stock price. However, concerns about future growth prospects weighed on investor sentiment. The CEO announced plans to diversify the company's product portfolio and expand into new markets, aiming to sustain long-term profitability. The marketing team launched a new advertising campaign to promote the company's flagship product, targeting key demographics. Despite challenges in the competitive landscape, the company remains committed to innovation and customer satisfaction.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"Announce\", \n",
    "    \"Aim\",\n",
    "    \"Earnings\",\n",
    "    \"Quarter\",\n",
    "    \"Report\",\n",
    "    \"Investor\",\n",
    "    \"Analysis\",\n",
    "    \"Market\",\n",
    "    \"Diversity\",\n",
    "    \"Product portfolio\",\n",
    "    \"Advertisment\",\n",
    "    \"Stock\",\n",
    "    \"Landscpe\" # yes, this is here on purpose\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Show solution</summary>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Announce', False),\n",
      " ('Aim', False),\n",
      " ('Earnings', True),\n",
      " ('Quarter', False),\n",
      " ('Report', False),\n",
      " ('Investor', True),\n",
      " ('Analysis', False),\n",
      " ('Market', False),\n",
      " ('Diversity', False),\n",
      " ('Product portfolio', False),\n",
      " ('Advertisment', False),\n",
      " ('Stock', True),\n",
      " ('Landscpe', False)]\n",
      "\n",
      "Detected 3/13 words.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "text_token = wordpunct_tokenize(text=text.lower())\n",
    "detected_words = [\n",
    "    (keyword, keyword.lower() in text_token) for keyword in keywords\n",
    "]\n",
    "pprint(detected_words)\n",
    "print(f\"\\nDetected {sum([x[1] for x in detected_words])}/{len(keywords)} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Announce', False),\n",
      " ('Aim', False),\n",
      " ('Earnings', True),\n",
      " ('Quarter', False),\n",
      " ('Report', True),\n",
      " ('Investor', True),\n",
      " ('Analysis', False),\n",
      " ('Market', True),\n",
      " ('Diversity', False),\n",
      " ('Product portfolio', False),\n",
      " ('Advertisment', False),\n",
      " ('Stock', True),\n",
      " ('Landscpe', False)]\n",
      "\n",
      "Detected 5/13 words.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_text_token = [\n",
    "    wnl.lemmatize(w) for w in text_token\n",
    "]\n",
    "detected_words = [\n",
    "    (keyword, keyword.lower() in lemmatized_text_token) for keyword in keywords\n",
    "]\n",
    "pprint(detected_words)\n",
    "print(f\"\\nDetected {sum([x[1] for x in detected_words])}/{len(keywords)} words.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Announce', True),\n",
      " ('Aim', True),\n",
      " ('Earnings', True),\n",
      " ('Quarter', False),\n",
      " ('Report', True),\n",
      " ('Investor', True),\n",
      " ('Analysis', False),\n",
      " ('Market', True),\n",
      " ('Diversity', False),\n",
      " ('Product portfolio', False),\n",
      " ('Advertisment', False),\n",
      " ('Stock', True),\n",
      " ('Landscpe', False)]\n",
      "\n",
      "Detected 7/13 words.\n"
     ]
    }
   ],
   "source": [
    "fully_lemmatized_text_token = []\n",
    "\n",
    "for token in text_token:\n",
    "    lemmatized_token = token\n",
    "    for pos in [\"n\", \"v\", \"a\"]:\n",
    "        lemmatized_token = wnl.lemmatize(token, pos=pos)\n",
    "        \n",
    "        fully_lemmatized_text_token.append(lemmatized_token)\n",
    "\n",
    "detected_words = [\n",
    "    (keyword, keyword.lower() in fully_lemmatized_text_token) for keyword in keywords\n",
    "]\n",
    "pprint(detected_words)    \n",
    "print(f\"\\nDetected {sum([x[1] for x in detected_words])}/{len(keywords)} words.\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "script_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
